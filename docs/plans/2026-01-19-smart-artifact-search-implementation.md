# Smart Artifact Search Implementation Plan

> **For Claude:** REQUIRED SUB-SKILL: Use superpowers:executing-plans to implement this plan task-by-task.

**Goal:** Implement project-aware artifact search that stops at project boundaries, detects monorepos, and presents results hierarchically.

**Architecture:** Two-phase algorithm (project discovery + artifact collection) using find with -prune for intelligent path pruning. Shared libraries for project detection and monorepo handling.

**Tech Stack:** Bash 3.2, find, grep, jq (for JSON parsing), parallel arrays for data structures

---

## Phase 1: Foundation - Project Detection Library

### Task 1: Create lib directory and project-detection.sh

**Files:**
- Create: `lib/project-detection.sh`

**Step 1: Create lib directory**

```bash
mkdir -p lib
```

**Step 2: Create project-detection.sh with header and data structures**

```bash
#!/bin/bash

################################################################################
# Project Detection Library - Detect project markers and types
#
# Description:
#   Scans directories for project markers (package.json, pyproject.toml, etc.)
#   and identifies project types and monorepo configurations
################################################################################

set -eo pipefail

# Project registry (parallel arrays for Bash 3.2)
PROJECT_PATHS=()           # /path/to/project
PROJECT_TYPES=()           # "js", "python", "mixed", "git"
PROJECT_MONOREPO_STATUS=() # "monorepo-root", "workspace", "standalone"
PROJECT_PARENT_MONO=()     # Parent monorepo path or empty

################################################################################
# Project Marker Definitions
################################################################################

# JavaScript markers
JS_MARKERS=("package.json" "pnpm-workspace.yaml" "lerna.json" "nx.json" "turbo.json")

# Python markers
PYTHON_MARKERS=("pyproject.toml" "setup.py" "requirements.txt" "Pipfile" "poetry.lock")

# Universal markers
UNIVERSAL_MARKERS=(".git")
```

**Step 3: Verify file created**

```bash
ls -la lib/project-detection.sh
```

Expected: File exists with correct permissions

**Step 4: Make executable**

```bash
chmod +x lib/project-detection.sh
```

**Step 5: Commit**

```bash
git add lib/project-detection.sh
git commit -m "feat: create project detection library with data structures"
```

---

### Task 2: Add project marker detection functions

**Files:**
- Modify: `lib/project-detection.sh`

**Step 1: Add function to check if directory has JS markers**

```bash
# Check if directory contains JavaScript project markers
has_js_markers() {
    local dir_path="$1"
    local marker

    for marker in "${JS_MARKERS[@]}"; do
        if [[ -f "$dir_path/$marker" ]]; then
            return 0  # Found JS marker
        fi
    done

    return 1  # No JS markers found
}
```

**Step 2: Add function to check if directory has Python markers**

```bash
# Check if directory contains Python project markers
has_python_markers() {
    local dir_path="$1"
    local marker

    for marker in "${PYTHON_MARKERS[@]}"; do
        if [[ -f "$dir_path/$marker" ]]; then
            return 0  # Found Python marker
        fi
    done

    return 1  # No Python markers found
}
```

**Step 3: Add function to check if directory has universal markers**

```bash
# Check if directory contains universal markers (like .git)
has_universal_markers() {
    local dir_path="$1"
    local marker

    for marker in "${UNIVERSAL_MARKERS[@]}"; do
        if [[ -d "$dir_path/$marker" ]] || [[ -f "$dir_path/$marker" ]]; then
            return 0  # Found universal marker
        fi
    done

    return 1  # No universal markers found
}
```

**Step 4: Add function to determine project type**

```bash
# Determine project type for a directory
# Returns: "js", "python", "mixed", "git", or "none"
get_project_type() {
    local dir_path="$1"
    local has_js=false
    local has_python=false
    local has_git=false

    if has_js_markers "$dir_path"; then
        has_js=true
    fi

    if has_python_markers "$dir_path"; then
        has_python=true
    fi

    if has_universal_markers "$dir_path"; then
        has_git=true
    fi

    # Determine type based on markers found
    if [[ "$has_js" == "true" ]] && [[ "$has_python" == "true" ]]; then
        echo "mixed"
    elif [[ "$has_js" == "true" ]]; then
        echo "js"
    elif [[ "$has_python" == "true" ]]; then
        echo "python"
    elif [[ "$has_git" == "true" ]]; then
        echo "git"
    else
        echo "none"
    fi
}
```

**Step 5: Test the functions manually**

```bash
# Source the library
source lib/project-detection.sh

# Test on current directory
get_project_type "."
```

Expected: Should return "none" or "git" depending on presence of .git

**Step 6: Commit**

```bash
git add lib/project-detection.sh
git commit -m "feat: add project marker detection functions"
```

---

### Task 3: Add monorepo detection functions

**Files:**
- Modify: `lib/project-detection.sh`

**Step 1: Add function to check if package.json has workspaces**

```bash
# Check if package.json contains workspaces configuration
# Returns: 0 if workspaces found, 1 otherwise
has_npm_workspaces() {
    local dir_path="$1"
    local package_json="$dir_path/package.json"

    if [[ ! -f "$package_json" ]]; then
        return 1
    fi

    # Check for workspaces field using grep (avoid jq dependency for now)
    if grep -q '"workspaces"' "$package_json" 2>/dev/null; then
        return 0
    fi

    return 1
}
```

**Step 2: Add function to check for pnpm workspaces**

```bash
# Check if directory has pnpm-workspace.yaml
has_pnpm_workspaces() {
    local dir_path="$1"

    if [[ -f "$dir_path/pnpm-workspace.yaml" ]]; then
        return 0
    fi

    return 1
}
```

**Step 3: Add function to check for lerna monorepo**

```bash
# Check if directory has lerna.json
has_lerna_workspaces() {
    local dir_path="$1"

    if [[ -f "$dir_path/lerna.json" ]]; then
        return 0
    fi

    return 1
}
```

**Step 4: Add function to check for nx monorepo**

```bash
# Check if directory has nx.json
has_nx_workspaces() {
    local dir_path="$1"

    if [[ -f "$dir_path/nx.json" ]]; then
        return 0
    fi

    return 1
}
```

**Step 5: Add function to check for turbo monorepo**

```bash
# Check if directory has turbo.json
has_turbo_workspaces() {
    local dir_path="$1"

    if [[ -f "$dir_path/turbo.json" ]]; then
        return 0
    fi

    return 1
}
```

**Step 6: Add function to determine if directory is monorepo root**

```bash
# Check if directory is a monorepo root
# Returns: 0 if monorepo, 1 otherwise
is_monorepo_root() {
    local dir_path="$1"

    if has_npm_workspaces "$dir_path" || \
       has_pnpm_workspaces "$dir_path" || \
       has_lerna_workspaces "$dir_path" || \
       has_nx_workspaces "$dir_path" || \
       has_turbo_workspaces "$dir_path"; then
        return 0
    fi

    return 1
}
```

**Step 7: Commit**

```bash
git add lib/project-detection.sh
git commit -m "feat: add monorepo detection functions"
```

---

## Phase 2: Core Algorithm - Artifact Search Library

### Task 4: Create artifact-search-core.sh

**Files:**
- Create: `lib/artifact-search-core.sh`

**Step 1: Create artifact-search-core.sh with header**

```bash
#!/bin/bash

################################################################################
# Artifact Search Core Library - Project-aware artifact search with pruning
#
# Description:
#   Implements two-phase search algorithm:
#   1. Project discovery - find and categorize project roots
#   2. Artifact collection - find artifacts with intelligent pruning
################################################################################

set -eo pipefail

# Source project detection library
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
source "$SCRIPT_DIR/project-detection.sh"

# Artifact registry (parallel arrays for Bash 3.2)
ARTIFACT_PATHS=()          # /path/to/artifact
ARTIFACT_TYPES=()          # "node_modules", ".venv", etc.
ARTIFACT_PROJECTS=()       # Associated project path
ARTIFACT_SIZES=()          # Calculated size

# Artifact type definitions
NODE_ARTIFACTS=("node_modules" "bower_components" ".pnpm-store")
PYTHON_ARTIFACTS=(".venv" "venv" "env" ".virtualenv")
```

**Step 2: Make executable**

```bash
chmod +x lib/artifact-search-core.sh
```

**Step 3: Verify file created**

```bash
ls -la lib/artifact-search-core.sh
```

Expected: File exists with execute permissions

**Step 4: Commit**

```bash
git add lib/artifact-search-core.sh
git commit -m "feat: create artifact search core library skeleton"
```

---

### Task 5: Add artifact validation function

**Files:**
- Modify: `lib/artifact-search-core.sh`

**Step 1: Add function to check if artifact matches project type**

```bash
# Check if artifact type matches project type
# Args: artifact_name, project_type
# Returns: 0 if valid match, 1 otherwise
artifact_matches_project() {
    local artifact_name="$1"
    local project_type="$2"
    local artifact

    # Universal markers (.git) match any artifact
    if [[ "$project_type" == "git" ]] || [[ "$project_type" == "mixed" ]]; then
        return 0
    fi

    # Check if artifact is a Node artifact and project is JS
    if [[ "$project_type" == "js" ]]; then
        for artifact in "${NODE_ARTIFACTS[@]}"; do
            if [[ "$artifact_name" == "$artifact" ]]; then
                return 0
            fi
        done
    fi

    # Check if artifact is a Python artifact and project is Python
    if [[ "$project_type" == "python" ]]; then
        for artifact in "${PYTHON_ARTIFACTS[@]}"; do
            if [[ "$artifact_name" == "$artifact" ]]; then
                return 0
            fi
        done
    fi

    return 1  # No match
}
```

**Step 2: Test the function manually**

```bash
source lib/artifact-search-core.sh

# Test matching
if artifact_matches_project "node_modules" "js"; then
    echo "PASS: node_modules matches js"
fi

if artifact_matches_project ".venv" "python"; then
    echo "PASS: .venv matches python"
fi

if ! artifact_matches_project "node_modules" "python"; then
    echo "PASS: node_modules does not match python"
fi
```

Expected: All three PASS messages

**Step 3: Commit**

```bash
git add lib/artifact-search-core.sh
git commit -m "feat: add artifact-project matching validation"
```

---

### Task 6: Add project discovery function

**Files:**
- Modify: `lib/artifact-search-core.sh`

**Step 1: Add function to find parent project for a path**

```bash
# Find the nearest parent directory that is a project root
# Args: directory_path
# Returns: project_path or empty string if none found
find_parent_project() {
    local current_path="$1"

    # Walk up directory tree
    while [[ "$current_path" != "/" ]]; do
        local project_type=$(get_project_type "$current_path")

        if [[ "$project_type" != "none" ]]; then
            echo "$current_path"
            return 0
        fi

        # Move to parent directory
        current_path="$(dirname "$current_path")"
    done

    # No project found
    echo ""
    return 1
}
```

**Step 2: Test the function**

```bash
source lib/artifact-search-core.sh

# Test finding project (should find repo root or none)
parent=$(find_parent_project "$(pwd)")
echo "Parent project: $parent"
```

Expected: Should print repo root path or empty

**Step 3: Commit**

```bash
git add lib/artifact-search-core.sh
git commit -m "feat: add parent project discovery function"
```

---

### Task 7: Add smart artifact search with pruning

**Files:**
- Modify: `lib/artifact-search-core.sh`

**Step 1: Add function to build find command with pruning**

```bash
# Build find command that prunes artifact directories
# Args: search_path, artifact_names_array
# Outputs: paths to artifacts (one per line)
find_artifacts_with_pruning() {
    local search_path="$1"
    shift
    local artifact_names=("$@")

    # Build find command
    local find_cmd="find \"$search_path\" -type d ! -type l"

    # Add artifact name patterns
    local first=true
    find_cmd="$find_cmd \\("
    for artifact in "${artifact_names[@]}"; do
        if [[ "$first" == "true" ]]; then
            find_cmd="$find_cmd -name \"$artifact\""
            first=false
        else
            find_cmd="$find_cmd -o -name \"$artifact\""
        fi
    done
    find_cmd="$find_cmd \\) -print -prune"

    # Add exclusions for system directories
    find_cmd="$find_cmd ! -path '*/Library/*' ! -path '*/Applications/*' ! -path '*/System/*'"
    find_cmd="$find_cmd ! -path '*/.Trash/*' ! -path '*/Downloads/*'"
    find_cmd="$find_cmd 2>/dev/null"

    # Execute find
    eval "$find_cmd"
}
```

**Step 2: Add function to search for specific artifact type**

```bash
# Search for artifacts of a specific type with project validation
# Args: search_path, artifact_type ("node" or "python")
search_artifacts_by_type() {
    local search_path="$1"
    local artifact_type="$2"
    local artifacts_array=()

    # Determine which artifacts to search for
    if [[ "$artifact_type" == "node" ]]; then
        artifacts_array=("${NODE_ARTIFACTS[@]}")
    elif [[ "$artifact_type" == "python" ]]; then
        artifacts_array=("${PYTHON_ARTIFACTS[@]}")
    else
        echo "Error: Unknown artifact type: $artifact_type" >&2
        return 1
    fi

    # Find artifacts with pruning
    while IFS= read -r artifact_path; do
        [[ -z "$artifact_path" ]] && continue

        # Get artifact name
        local artifact_name="$(basename "$artifact_path")"

        # Find parent project
        local parent_dir="$(dirname "$artifact_path")"
        local parent_project=$(find_parent_project "$parent_dir")

        if [[ -n "$parent_project" ]]; then
            # Get project type
            local project_type=$(get_project_type "$parent_project")

            # Validate artifact matches project type
            if artifact_matches_project "$artifact_name" "$project_type"; then
                # Record artifact
                ARTIFACT_PATHS+=("$artifact_path")
                ARTIFACT_TYPES+=("$artifact_name")
                ARTIFACT_PROJECTS+=("$parent_project")
                echo "$artifact_path"
            fi
        fi

    done < <(find_artifacts_with_pruning "$search_path" "${artifacts_array[@]}")
}
```

**Step 3: Commit**

```bash
git add lib/artifact-search-core.sh
git commit -m "feat: add smart artifact search with pruning and validation"
```

---

## Phase 3: Monorepo Handling Library

### Task 8: Create monorepo-handler.sh

**Files:**
- Create: `lib/monorepo-handler.sh`

**Step 1: Create monorepo-handler.sh with header**

```bash
#!/bin/bash

################################################################################
# Monorepo Handler Library - Group and format monorepo artifacts
#
# Description:
#   Handles monorepo detection, workspace grouping, and hierarchical output
################################################################################

set -eo pipefail

# Monorepo registry
MONOREPO_ROOTS=()          # Paths to monorepo roots
MONOREPO_ARTIFACTS=()      # Comma-separated artifact paths per monorepo

################################################################################
# Grouping Functions
################################################################################

# Group artifacts by monorepo
# Reads from global ARTIFACT_PATHS and ARTIFACT_PROJECTS arrays
group_artifacts_by_monorepo() {
    local i
    local processed_monorepos=()

    for i in "${!ARTIFACT_PATHS[@]}"; do
        local artifact_path="${ARTIFACT_PATHS[$i]}"
        local project_path="${ARTIFACT_PROJECTS[$i]}"

        # Skip if already processed
        [[ " ${processed_monorepos[@]} " =~ " ${project_path} " ]] && continue

        # Check if project is monorepo
        source "$(dirname "${BASH_SOURCE[0]}")/project-detection.sh"
        if is_monorepo_root "$project_path"; then
            # Find all artifacts under this monorepo
            local mono_artifacts=()
            local j
            for j in "${!ARTIFACT_PATHS[@]}"; do
                local check_path="${ARTIFACT_PATHS[$j]}"
                # Check if artifact is under this monorepo
                if [[ "$check_path" == "$project_path"* ]]; then
                    mono_artifacts+=("$check_path")
                fi
            done

            # Store monorepo info
            MONOREPO_ROOTS+=("$project_path")
            MONOREPO_ARTIFACTS+=("$(IFS=,; echo "${mono_artifacts[*]}")")
            processed_monorepos+=("$project_path")
        fi
    done
}
```

**Step 2: Make executable**

```bash
chmod +x lib/monorepo-handler.sh
```

**Step 3: Commit**

```bash
git add lib/monorepo-handler.sh
git commit -m "feat: create monorepo handler library with grouping"
```

---

### Task 9: Add monorepo output formatting

**Files:**
- Modify: `lib/monorepo-handler.sh`

**Step 1: Add function to format monorepo output (â‰¤3 artifacts)**

```bash
# Format monorepo output with expanded artifacts
# Args: monorepo_path, artifacts_csv, total_size
format_monorepo_expanded() {
    local monorepo_path="$1"
    local artifacts_csv="$2"
    local total_size="$3"

    # Split CSV into array
    IFS=',' read -ra artifacts <<< "$artifacts_csv"
    local count=${#artifacts[@]}

    echo -e "${CYAN}Monorepo: $monorepo_path ($count artifacts, $total_size)${RESET}"

    # Display each artifact with tree indicators
    local i
    for i in "${!artifacts[@]}"; do
        local artifact="${artifacts[$i]}"
        local size=$(du -sh "$artifact" 2>/dev/null | cut -f1)

        if [[ $i -eq $((count - 1)) ]]; then
            # Last item
            printf "  â””â”€ %-70s ${GREEN}(%s)${RESET}\\n" "$artifact" "$size"
        else
            # Not last item
            printf "  â”œâ”€ %-70s ${GREEN}(%s)${RESET}\\n" "$artifact" "$size"
        fi
    done
    echo ""
}
```

**Step 2: Add function to format monorepo output (>3 artifacts)**

```bash
# Format monorepo output with summary
# Args: monorepo_path, artifacts_csv, total_size
format_monorepo_summary() {
    local monorepo_path="$1"
    local artifacts_csv="$2"
    local total_size="$3"

    # Split CSV into array
    IFS=',' read -ra artifacts <<< "$artifacts_csv"
    local count=${#artifacts[@]}

    echo -e "${CYAN}Monorepo: $monorepo_path ($total_size total, $count workspace artifacts)${RESET}"
    echo -e "  Details: Use 'pkgcheat -a-detail $monorepo_path' to see all workspaces"
    echo ""
}
```

**Step 3: Add function to choose format based on threshold**

```bash
# Format monorepo output (auto-choose format based on count)
# Args: monorepo_path, artifacts_csv
format_monorepo() {
    local monorepo_path="$1"
    local artifacts_csv="$2"
    local threshold=3

    # Split CSV into array
    IFS=',' read -ra artifacts <<< "$artifacts_csv"
    local count=${#artifacts[@]}

    # Calculate total size
    local total_size=$(du -shc "${artifacts[@]}" 2>/dev/null | tail -1 | cut -f1)

    if [[ $count -le $threshold ]]; then
        format_monorepo_expanded "$monorepo_path" "$artifacts_csv" "$total_size"
    else
        format_monorepo_summary "$monorepo_path" "$artifacts_csv" "$total_size"
    fi
}
```

**Step 4: Add color definitions at top of file**

```bash
# Add after set -eo pipefail line:

# Colors
CYAN='\033[0;36m'
GREEN='\033[0;32m'
RESET='\033[0m'
```

**Step 5: Commit**

```bash
git add lib/monorepo-handler.sh
git commit -m "feat: add monorepo output formatting functions"
```

---

## Phase 4: Integration - Update Scripts

### Task 10: Update list-all-artifacts.sh to use new libraries

**Files:**
- Modify: `list-all-artifacts.sh`

**Step 1: Add library sourcing at top of file (after color definitions)**

```bash
# Source shared libraries
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
source "$SCRIPT_DIR/lib/artifact-search-core.sh"
source "$SCRIPT_DIR/lib/monorepo-handler.sh"
```

**Step 2: Replace find_artifacts function with call to library**

Find the `find_artifacts()` function and replace with:

```bash
# Find artifacts with smart pruning (uses library)
find_artifacts() {
    local search_path="$1"
    local artifact_name="$2"

    # Determine artifact type
    local artifact_type=""
    for node_art in "${NODE_ARTIFACTS[@]}"; do
        if [[ "$artifact_name" == "$node_art" ]]; then
            artifact_type="node"
            break
        fi
    done

    if [[ -z "$artifact_type" ]]; then
        for py_art in "${PYTHON_ARTIFACTS[@]}"; do
            if [[ "$artifact_name" == "$py_art" ]]; then
                artifact_type="python"
                break
            fi
        done
    fi

    # Use library function
    if [[ -n "$artifact_type" ]]; then
        search_artifacts_by_type "$search_path" "$artifact_type"
    fi
}
```

**Step 3: Test the updated script**

```bash
./list-all-artifacts.sh /tmp/pkgcheat-test 2>&1 | head -20
```

Expected: Should run without errors (may find no artifacts if test dir doesn't exist)

**Step 4: Commit**

```bash
git add list-all-artifacts.sh
git commit -m "refactor: integrate artifact-search-core library into list-all-artifacts"
```

---

### Task 11: Add monorepo grouping to display

**Files:**
- Modify: `list-all-artifacts.sh`

**Step 1: Update display_results function to group by monorepo**

Replace `display_results()` function with:

```bash
# Display formatted results with monorepo grouping
display_results() {
    local search_path="$1"
    local total_size="0B"
    local all_paths=()

    # Group artifacts by monorepo
    group_artifacts_by_monorepo

    # Track which artifacts are displayed as part of monorepo
    local displayed_artifacts=()

    # Display monorepos first
    if [[ ${#MONOREPO_ROOTS[@]} -gt 0 ]]; then
        local i
        for i in "${!MONOREPO_ROOTS[@]}"; do
            local mono_root="${MONOREPO_ROOTS[$i]}"
            local mono_artifacts="${MONOREPO_ARTIFACTS[$i]}"

            format_monorepo "$mono_root" "$mono_artifacts"

            # Mark these artifacts as displayed
            IFS=',' read -ra arts <<< "$mono_artifacts"
            displayed_artifacts+=("${arts[@]}")
        done
    fi

    # Display standalone artifacts (not in monorepos)
    echo -e "${BOLD}${CYAN}â”â”â” Standalone Projects â”â”â”${RESET}"
    echo ""

    local i
    for i in "${!artifact_paths[@]}"; do
        local path="${artifact_paths[$i]}"

        # Skip if already displayed in monorepo
        if [[ " ${displayed_artifacts[@]} " =~ " ${path} " ]]; then
            continue
        fi

        local size=$(calculate_size "$path")
        printf "%-70s ${GREEN}(%s)${RESET}\\n" "$path" "$size"
        all_paths+=("$path")
    done

    echo ""

    # Calculate and display total
    all_paths+=("${displayed_artifacts[@]}")
    total_size=$(calculate_total_size "${all_paths[@]}")
    echo -e "${BOLD}${GREEN}âœ“ Complete! Found ${#all_paths[@]} artifacts using $total_size total${RESET}"
    echo ""
}
```

**Step 2: Commit**

```bash
git add list-all-artifacts.sh
git commit -m "feat: add monorepo grouping to artifact display"
```

---

### Task 12: Create test directory structure for validation

**Files:**
- None (testing only)

**Step 1: Create test monorepo structure**

```bash
mkdir -p /tmp/pkgcheat-test-mono/packages/app1
mkdir -p /tmp/pkgcheat-test-mono/packages/app2
mkdir -p /tmp/pkgcheat-test-mono/node_modules
mkdir -p /tmp/pkgcheat-test-mono/packages/app1/node_modules
mkdir -p /tmp/pkgcheat-test-mono/packages/app2/node_modules

# Create package.json with workspaces
cat > /tmp/pkgcheat-test-mono/package.json <<'EOF'
{
  "name": "test-monorepo",
  "workspaces": ["packages/*"]
}
EOF

cat > /tmp/pkgcheat-test-mono/packages/app1/package.json <<'EOF'
{
  "name": "app1"
}
EOF

cat > /tmp/pkgcheat-test-mono/packages/app2/package.json <<'EOF'
{
  "name": "app2"
}
EOF
```

**Step 2: Create standalone project**

```bash
mkdir -p /tmp/pkgcheat-test-standalone/node_modules
cat > /tmp/pkgcheat-test-standalone/package.json <<'EOF'
{
  "name": "standalone-app"
}
EOF
```

**Step 3: Test the script on test structure**

```bash
./list-all-artifacts.sh /tmp/pkgcheat-test-mono
```

Expected: Should show monorepo with 3 artifacts grouped

**Step 4: Test on standalone**

```bash
./list-all-artifacts.sh /tmp
```

Expected: Should show both monorepo (grouped) and standalone project

**Step 5: No commit needed (testing only)**

---

## Phase 5: Polish and Migration

### Task 13: Add CLI flags support

**Files:**
- Modify: `list-all-artifacts.sh`

**Step 1: Add flag parsing for --legacy-mode**

Add after argument parsing section:

```bash
# Feature flags
LEGACY_MODE=false
NO_CACHE=false
VERBOSE=false
FOLLOW_SYMLINKS=false

# Parse flags
while [[ $# -gt 0 ]]; do
    case $1 in
        --legacy-mode)
            LEGACY_MODE=true
            shift
            ;;
        --no-cache)
            NO_CACHE=true
            shift
            ;;
        --verbose)
            VERBOSE=true
            shift
            ;;
        --follow-symlinks)
            FOLLOW_SYMLINKS=true
            shift
            ;;
        --sort=*)
            SORT_BY="${1#*=}"
            shift
            ;;
        --help|-h)
            echo "Usage: $0 [path] [OPTIONS]"
            echo ""
            echo "Options:"
            echo "  path                  Directory to search (default: current directory)"
            echo "  --sort=METHOD         Sort by: size, path, or date (default: size)"
            echo "  --legacy-mode         Use old exhaustive search algorithm"
            echo "  --no-cache            Force fresh scan, ignore cache"
            echo "  --verbose             Show pruning decisions"
            echo "  --follow-symlinks     Follow symlinked artifacts"
            echo "  --help, -h            Show this help message"
            exit 0
            ;;
        *)
            if [[ -z "$SEARCH_PATH" ]]; then
                SEARCH_PATH="$1"
            fi
            shift
            ;;
    esac
done
```

**Step 2: Add legacy mode fallback**

Add function to use old algorithm:

```bash
# Legacy search mode (old exhaustive algorithm)
search_legacy_mode() {
    local search_path="$1"

    echo -e "${YELLOW}Using legacy search mode (exhaustive)...${RESET}"

    # Use old find command without pruning
    # (Keep existing find_artifacts implementation as fallback)
}
```

**Step 3: Update main to check LEGACY_MODE flag**

```bash
main() {
    validate_sort_method

    if [[ "$LEGACY_MODE" == "true" ]]; then
        search_legacy_mode "$SEARCH_PATH"
    else
        search_all_artifacts "$SEARCH_PATH"
    fi
}
```

**Step 4: Test with --legacy-mode flag**

```bash
./list-all-artifacts.sh /tmp/pkgcheat-test-mono --legacy-mode
```

Expected: Should show legacy mode message

**Step 5: Commit**

```bash
git add list-all-artifacts.sh
git commit -m "feat: add CLI flags support (legacy-mode, verbose, no-cache)"
```

---

### Task 14: Update README with new behavior

**Files:**
- Modify: `README.md`

**Step 1: Update Artifact Discovery section**

Replace the artifact discovery section with:

```markdown
### Artifact Discovery

**New in v2.0:** Smart project-aware search that stops at project boundaries and groups monorepo workspaces!

Find project dependencies and virtual environments with intelligent pruning:

**Interactive Mode:**
```bash
pkgcheat
# Select "Show project artifacts (node_modules, .venv, etc.)"
```

**Command Line:**
```bash
pkgcheat -a [path]              # Smart search (new algorithm)
pkgcheat -a-detail [path]       # Expand summarized monorepos
pkgcheat -a [path] --legacy-mode   # Use old exhaustive search
pkgcheat -a [path] --verbose    # Show pruning decisions
```

**What's New:**
- ðŸš€ **Faster:** Stops at project boundaries, no nested searching
- ðŸŽ¯ **Smarter:** Matches artifacts to project types (JS/Python/Mixed)
- ðŸ“¦ **Monorepo-aware:** Detects and groups workspace artifacts
- ðŸŒ³ **Hierarchical output:** Tree-style display for better clarity

**Example Output:**
```
â”â”â” node_modules - JavaScript dependencies (4 found, 1.2GB total) â”â”â”

Monorepo: /projects/my-monorepo (3 artifacts, 850MB)
  â”œâ”€ /projects/my-monorepo/node_modules (500MB)
  â”œâ”€ /projects/my-monorepo/packages/app1/node_modules (200MB)
  â””â”€ /projects/my-monorepo/packages/app2/node_modules (150MB)

â”â”â” Standalone Projects â”â”â”

/projects/standalone-app/node_modules (350MB)
```
```

**Step 2: Add migration notice**

Add new section:

```markdown
### Migration from v1.x

**Breaking Change:** The artifact search now stops at project boundaries and no longer reports nested dependencies (e.g., `node_modules/package/node_modules`).

If you need the old behavior:
```bash
pkgcheat -a [path] --legacy-mode
```

**Benefits of new algorithm:**
- âœ… 10-100x faster on large directory trees
- âœ… Cleaner output (no irrelevant nested artifacts)
- âœ… Monorepo awareness
- âœ… Project-type validation
```

**Step 3: Commit**

```bash
git add README.md
git commit -m "docs: update README with v2.0 smart search features"
```

---

### Task 15: Update list-node-modules.sh and list-python-venvs.sh

**Files:**
- Modify: `list-node-modules.sh`
- Modify: `list-python-venvs.sh`

**Step 1: Update list-node-modules.sh to use library**

Add library sourcing and update find function:

```bash
# Source shared libraries
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
source "$SCRIPT_DIR/lib/artifact-search-core.sh"
source "$SCRIPT_DIR/lib/monorepo-handler.sh"

# Update find_artifacts to use library
find_artifacts() {
    local search_path="$1"
    local artifact_name="$2"

    search_artifacts_by_type "$search_path" "node"
}
```

**Step 2: Update list-python-venvs.sh to use library**

```bash
# Source shared libraries
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
source "$SCRIPT_DIR/lib/artifact-search-core.sh"
source "$SCRIPT_DIR/lib/monorepo-handler.sh"

# Update find_artifacts to use library
find_artifacts() {
    local search_path="$1"
    local artifact_name="$2"

    search_artifacts_by_type "$search_path" "python"
}
```

**Step 3: Test both scripts**

```bash
./list-node-modules.sh /tmp/pkgcheat-test-mono
./list-python-venvs.sh /tmp
```

Expected: Both should work with new algorithm

**Step 4: Commit**

```bash
git add list-node-modules.sh list-python-venvs.sh
git commit -m "refactor: update specialized scripts to use shared libraries"
```

---

## Phase 6: Testing and Validation

### Task 16: Comprehensive testing

**Files:**
- None (testing only)

**Step 1: Test on real monorepo**

```bash
# Test on actual projects directory
./list-all-artifacts.sh ~/Documents/Code
```

Expected: Should show monorepos grouped, faster than before

**Step 2: Test performance comparison**

```bash
# Time old algorithm
time ./list-all-artifacts.sh ~/Documents/Code --legacy-mode > /dev/null

# Time new algorithm
time ./list-all-artifacts.sh ~/Documents/Code > /dev/null
```

Expected: New algorithm significantly faster

**Step 3: Test edge cases**

```bash
# Test empty directory
./list-all-artifacts.sh /tmp/empty-test-dir

# Test mixed project
mkdir -p /tmp/mixed-project/{node_modules,.venv}
touch /tmp/mixed-project/package.json
touch /tmp/mixed-project/pyproject.toml
./list-all-artifacts.sh /tmp/mixed-project
```

Expected: Handles edge cases gracefully

**Step 4: Clean up test directories**

```bash
rm -rf /tmp/pkgcheat-test-mono
rm -rf /tmp/pkgcheat-test-standalone
rm -rf /tmp/mixed-project
```

**Step 5: No commit needed (testing only)**

---

### Task 17: Final integration test

**Files:**
- None (testing only)

**Step 1: Run all three scripts on test data**

```bash
# Create comprehensive test structure
mkdir -p /tmp/final-test/{mono,standalone,python-proj}
mkdir -p /tmp/final-test/mono/{node_modules,packages/app1/node_modules}
mkdir -p /tmp/final-test/standalone/node_modules
mkdir -p /tmp/final-test/python-proj/.venv

echo '{"workspaces":["packages/*"]}' > /tmp/final-test/mono/package.json
echo '{}' > /tmp/final-test/mono/packages/app1/package.json
echo '{}' > /tmp/final-test/standalone/package.json
echo '[tool.poetry]' > /tmp/final-test/python-proj/pyproject.toml
```

**Step 2: Test all three scripts**

```bash
./list-all-artifacts.sh /tmp/final-test
./list-node-modules.sh /tmp/final-test
./list-python-venvs.sh /tmp/final-test
```

Expected: All scripts work correctly with new algorithm

**Step 3: Verify output format**

Check that:
- Monorepo is grouped properly
- Standalone projects shown separately
- Tree indicators (â”œâ”€, â””â”€) display correctly
- Sizes calculated correctly

**Step 4: Clean up**

```bash
rm -rf /tmp/final-test
```

**Step 5: Final commit**

```bash
git add -A
git commit -m "test: validate all scripts with comprehensive test cases"
```

---

## Success Criteria

- âœ… Libraries created and functional
- âœ… Project detection works for JS, Python, mixed, git markers
- âœ… Monorepo detection works for npm, pnpm, lerna, nx, turbo
- âœ… Artifact search uses pruning (no nested searches)
- âœ… Artifacts validated against project types
- âœ… Monorepo grouping works (â‰¤3 expanded, >3 summarized)
- âœ… CLI flags implemented (--legacy-mode, --verbose, --no-cache)
- âœ… All three scripts updated and working
- âœ… README updated with migration guide
- âœ… Performance significantly improved
- âœ… Tests pass on real-world projects

## Notes

- Use @superpowers:test-driven-development for any complex logic if needed
- Use @superpowers:systematic-debugging if issues arise
- Frequent small commits (one per step)
- Test each phase before moving to next
